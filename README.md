# CIS655-final-project: Image-Describing Website

This website, hosted on GCP, utilizes an App Engine backend and a Virtual Machine front end.  It also utilizes Googles Vision API, and Vertex AI.  It allows a user to upload an image from their computer and select the ways they want the image analyzed.  The project then displays the user-selected results, generated by image recognition and AI.  The project also utilized Cloud Build as a CI/CD platform.

## Services
### Cloud Build
I used Cloud Build in this project so I could use Visual Studio Code as my text editor instead of vim, and so I could keep a repository of my work.  I created the repository, and enabled Cloud Build on my project.  Then, I had to link the repo to my project, and add a trigger, so that any time I pushed to the project, the trigger would notice and initialize a build of the project.  To correctly build the project, cloudbuild required a document in my project called "cloudbuild.yaml", which specified the build steps required for the project.  Since I wanted both my frontend and backend in the same repository, it required two steps. 

The first step was for the frontend, hosted on a Virtual Machine.  I had to cd into the correct directory, and pull the most recent changes.  Then, because the virtual machine looked for index.html, the script, and the stylesheet in /var/www/html, I had to compy those document into that directory.  Then the machine could be restarted. For the backend, it was as easy as deploying the app.yaml file.  It was imperative however, that the service account used had the correct permissions, or it would not build

### Virtual Machine Instance
The Virtual Machine Instance was set up to be an e2-micro machine, since it did not need much power to host a website.  The HTML file just needed to display the the image, the checkboxes, and the results.  The script had to parse the checked boxes, and send the image and service data to the backend.  Once the results returned, the script had to parse the json response and send it to be displayed on the website.

### App Engine Instance
The App Engine Instance was used to host the backend of the website.  Since it was serverless, it took minimal setup and simply had to be enabled.  It ran a Python script that would recieve the image and service data from the frontend, determine what tasks had to be performed, and then send requests to the Vision and Vertex APIs.

### Vision API
The Vision API only had to be enabled in GCP to use it in my project.  The API required me to create an Image Annotator Client.  The client could use the annotat_image function which required the image data in bytes and a list of the features(label, writing, etc.).

### Vertex AI
Vertex AI was the final addition to this project.  First, I had to rebuild the image from the bytes that were sent from the frontend.  This was done using Python Magic to determine the mime type(jpeg, png, etc.) of the image using its bytes.  With this information, Vertex AI's library allowed the image to be rebuilt.  The generative model I used was Gemini 2.5, which released on March 25th.  I asked the model to describe the image and, if necessary, it could use image tags generated by the Vision API.
